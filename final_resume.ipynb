{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVYnotPLaosa",
        "outputId": "1f4f4a10-5ae2-44d6-c156-a56eaa784482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.11/dist-packages (23.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn) (24.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: requests-html in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.32.3)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.0.1)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.2.0)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.11/dist-packages (from requests-html) (1.20.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.11/dist-packages (from requests-html) (0.0.2)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.3.1)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.0.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (2025.1.31)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (8.6.1)\n",
            "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (11.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.67.1)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.26.20)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (10.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4->requests-html) (4.13.4)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyquery->requests-html) (5.3.2)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyquery->requests-html) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->requests-html) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->requests-html) (3.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html) (4.13.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4->requests-html) (2.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: tika in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tika) (75.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tika) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tika) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tika) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tika) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tika) (2025.1.31)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: zipfile36 in /usr/local/lib/python3.11/dist-packages (0.1.3)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.3\n"
          ]
        }
      ],
      "source": [
        "# Install Required Dependencies\n",
        "!pip install flask\n",
        "!pip install ftfy\n",
        "!pip install gunicorn\n",
        "!pip install nltk\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install regex\n",
        "!pip install requests\n",
        "!pip install requests-html\n",
        "!pip install scikit-learn\n",
        "!pip install scipy\n",
        "!pip install beautifulsoup4\n",
        "!pip install tika\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install fake-useragent\n",
        "!pip install openpyxl\n",
        "!pip install zipfile36\n",
        "!pip install xlsxwriter  # Add this line"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Required Libraries\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from tika import parser\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('brown')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF3Tf705apvX",
        "outputId": "5734f459-9d31-44eb-a769-9830823d3e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaningText(text):\n",
        "    text = text.replace('\\\\n', '\\n')\n",
        "    text = text.replace('\\\\t', '\\n')\n",
        "    text = text.replace('\\\\r', '\\n')\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = re.sub('http\\S+\\s*', ' ', text)\n",
        "    text = re.sub('RT|cc', ' ', text)\n",
        "    text = re.sub('#\\S+', ' ', text)\n",
        "    text = re.sub('@\\S+', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\x00-\\x7f]', \"\", text)\n",
        "    return text.strip().lower()\n",
        "\n",
        "def preprocessing(text):\n",
        "    return cleaningText(text)\n",
        "\n",
        "def vectorizing(skills, job):\n",
        "    count_matrix = []\n",
        "    for jobs in job:\n",
        "        text = [skills, jobs]\n",
        "        cv = TfidfVectorizer()\n",
        "        count_matrix.append(cv.fit_transform(text))\n",
        "    return count_matrix\n",
        "\n",
        "def coSim(vector):\n",
        "    matchPercentage = []\n",
        "    for vec in vector:\n",
        "        matchPercentage.append(cosine_similarity(vec)[0][1] * 100)\n",
        "        matchPercentage = [round(percent, 2) for percent in matchPercentage]\n",
        "    return matchPercentage"
      ],
      "metadata": {
        "id": "RNUJxBuTb3G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Create a list of common skills\n",
        "skill = [\n",
        "    # Programming Languages\n",
        "    \"python\", \"java\", \"javascript\", \"c++\", \"c#\", \"ruby\", \"php\", \"swift\", \"kotlin\", \"go\",\n",
        "    # Web Technologies\n",
        "    \"html\", \"css\", \"react\", \"angular\", \"vue.js\", \"node.js\", \"express.js\", \"django\", \"flask\",\n",
        "    \"bootstrap\", \"jquery\", \"rest api\", \"graphql\", \"xml\", \"json\",\n",
        "    # Databases\n",
        "    \"sql\", \"mysql\", \"postgresql\", \"mongodb\", \"oracle\", \"redis\", \"elasticsearch\",\n",
        "    # Cloud & DevOps\n",
        "    \"aws\", \"azure\", \"google cloud\", \"docker\", \"kubernetes\", \"jenkins\", \"git\", \"github\",\n",
        "    \"devops\", \"ci/cd\", \"linux\", \"unix\", \"bash\",\n",
        "    # Data Science & AI\n",
        "    \"machine learning\", \"deep learning\", \"artificial intelligence\", \"data analysis\",\n",
        "    \"pandas\", \"numpy\", \"scipy\", \"scikit-learn\", \"tensorflow\", \"pytorch\", \"keras\",\n",
        "    \"data visualization\", \"tableau\", \"power bi\",\n",
        "    # Mobile Development\n",
        "    \"android\", \"ios\", \"react native\", \"flutter\", \"xamarin\",\n",
        "    # Other Technical Skills\n",
        "    \"agile\", \"scrum\", \"jira\", \"testing\", \"debugging\", \"api development\",\n",
        "    \"microservices\", \"rest\", \"soap\", \"version control\",\n",
        "    # Soft Skills\n",
        "    \"problem solving\", \"team work\", \"communication\", \"leadership\", \"project management\",\n",
        "    \"time management\", \"analytical skills\", \"critical thinking\",\n",
        "    # Microsoft Office\n",
        "    \"microsoft office\", \"excel\", \"word\", \"powerpoint\", \"outlook\",\n",
        "    # Additional Tools\n",
        "    \"photoshop\", \"illustrator\", \"figma\", \"sketch\", \"adobe creative suite\",\n",
        "    # Frameworks\n",
        "    \"spring boot\", \"laravel\", \"asp.net\", \"ruby on rails\", \"symfony\",\n",
        "    # Testing\n",
        "    \"junit\", \"selenium\", \"pytest\", \"jest\", \"mocha\",\n",
        "    # Project Management\n",
        "    \"agile methodology\", \"scrum\", \"kanban\", \"waterfall\", \"prince2\",\n",
        "    # Security\n",
        "    \"cybersecurity\", \"encryption\", \"security\", \"penetration testing\", \"ethical hacking\",\n",
        "    # Analytics\n",
        "    \"google analytics\", \"seo\", \"data mining\", \"statistical analysis\", \"a/b testing\",\n",
        "    # Architecture\n",
        "    \"system design\", \"software architecture\", \"design patterns\", \"mvc\", \"rest\"\n",
        "]\n",
        "\n",
        "# Create skills matcher\n",
        "skillsmatcher = PhraseMatcher(nlp.vocab)\n",
        "patterns = [nlp.make_doc(text) for text in skill if len(nlp.make_doc(text)) < 10]\n",
        "skillsmatcher.add(\"Job title\", None, *patterns)\n",
        "\n",
        "def extract_skills(text):\n",
        "    skills = []\n",
        "    __nlp = nlp(text.lower())\n",
        "    matches = skillsmatcher(__nlp)\n",
        "    for match_id, start, end in matches:\n",
        "        span = __nlp[start:end]\n",
        "        skills.append(span.text)\n",
        "    skills = list(set(skills))\n",
        "    return skills\n",
        "\n",
        "def convert_pdf_to_txt(pdf_file):\n",
        "    raw_text = parser.from_file(pdf_file, service='text')['content']\n",
        "    full_string = re.sub(r'\\n+', '\\n', raw_text)\n",
        "    full_string = full_string.replace(\"\\r\", \"\\n\")\n",
        "    full_string = full_string.replace(\"\\t\", \" \")\n",
        "    full_string = re.sub(r\"\\uf0b7\", \" \", full_string)\n",
        "    full_string = re.sub(r\"\\(cid:\\d{0,2}\\)\", \" \", full_string)\n",
        "    full_string = re.sub(r'• ', \" \", full_string)\n",
        "    resume_lines = full_string.splitlines(True)\n",
        "    resume_lines = [re.sub('\\s+', ' ', line.strip()) for line in resume_lines if line.strip()]\n",
        "    return resume_lines"
      ],
      "metadata": {
        "id": "QQG-GNSNb-Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sample_jobs():\n",
        "    return [\n",
        "        {\n",
        "            'position': 'Software Engineer',\n",
        "            'company': 'Tech Corp',\n",
        "            'salary': '$80,000 - $120,000 a year',\n",
        "            'description': '''\n",
        "            Looking for a skilled Software Engineer with:\n",
        "            - Strong experience in Python, JavaScript, and web development\n",
        "            - Proficiency in React.js, Node.js, and modern web frameworks\n",
        "            - Experience with SQL databases and RESTful APIs\n",
        "            - Knowledge of AWS cloud services\n",
        "            - Familiarity with Git and CI/CD pipelines\n",
        "            - Good problem-solving and analytical skills\n",
        "            - Excellent communication and teamwork abilities\n",
        "            ''',\n",
        "        },\n",
        "        {\n",
        "            'position': 'Data Scientist',\n",
        "            'company': 'Data Analytics Inc',\n",
        "            'salary': '$90,000 - $130,000 a year',\n",
        "            'description': '''\n",
        "            Seeking an experienced Data Scientist with:\n",
        "            - Advanced Python programming skills\n",
        "            - Expertise in Machine Learning and Statistical Analysis\n",
        "            - Proficiency with Pandas, NumPy, Scikit-learn\n",
        "            - Experience with Big Data technologies\n",
        "            - Knowledge of SQL and data visualization\n",
        "            - Strong mathematical and analytical skills\n",
        "            - Excellent research and documentation abilities\n",
        "            ''',\n",
        "        },\n",
        "        {\n",
        "            'position': 'Full Stack Developer',\n",
        "            'company': 'Web Solutions Ltd',\n",
        "            'salary': '$85,000 - $125,000 a year',\n",
        "            'description': '''\n",
        "            Full Stack Developer position requiring:\n",
        "            - Expertise in JavaScript/TypeScript\n",
        "            - React.js and Node.js experience\n",
        "            - MongoDB and Express.js knowledge\n",
        "            - Strong HTML5 and CSS3 skills\n",
        "            - Experience with RESTful APIs\n",
        "            - Version control with Git\n",
        "            - Agile development methodology\n",
        "            ''',\n",
        "        },\n",
        "        {\n",
        "            'position': 'DevOps Engineer',\n",
        "            'company': 'Cloud Systems Inc',\n",
        "            'salary': '$95,000 - $140,000 a year',\n",
        "            'description': '''\n",
        "            Seeking DevOps Engineer with:\n",
        "            - Strong Linux/Unix administration skills\n",
        "            - Experience with Docker and Kubernetes\n",
        "            - AWS/Azure cloud platform expertise\n",
        "            - CI/CD pipeline implementation\n",
        "            - Infrastructure as Code (Terraform)\n",
        "            - Python/Shell scripting abilities\n",
        "            - Security best practices knowledge\n",
        "            ''',\n",
        "        },\n",
        "        {\n",
        "            'position': 'Frontend Developer',\n",
        "            'company': 'Creative Web Agency',\n",
        "            'salary': '$75,000 - $110,000 a year',\n",
        "            'description': '''\n",
        "            Frontend Developer position requiring:\n",
        "            - Advanced JavaScript and TypeScript\n",
        "            - React.js or Vue.js expertise\n",
        "            - Modern CSS and Sass\n",
        "            - Responsive design experience\n",
        "            - Web performance optimization\n",
        "            - Cross-browser compatibility\n",
        "            - UI/UX best practices\n",
        "            ''',\n",
        "        }\n",
        "    ]"
      ],
      "metadata": {
        "id": "qj1lCdMAcA84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_resume(resume_file):\n",
        "    try:\n",
        "        # Use sample data directly\n",
        "        results = get_sample_jobs()\n",
        "\n",
        "        # Create DataFrame directly from results\n",
        "        job_df = pd.DataFrame(results)\n",
        "        stopw = set(stopwords.words('english'))\n",
        "\n",
        "        # Process jobs\n",
        "        job_df['test'] = job_df['description'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stopw)]))\n",
        "        df = job_df.drop_duplicates(subset='test').reset_index(drop=True)\n",
        "        df['clean'] = df['test'].apply(preprocessing)\n",
        "        jobdesc = (df['clean'].values.astype('U'))\n",
        "\n",
        "        # Process resume\n",
        "        resume_text = \" \".join(convert_pdf_to_txt(resume_file))\n",
        "        skills = extract_skills(resume_text)\n",
        "        skills_text = ' '.join(skills)\n",
        "        skills_processed = preprocessing(skills_text)\n",
        "\n",
        "        # Calculate similarity\n",
        "        count_matrix = vectorizing(skills_processed, jobdesc)\n",
        "        matchPercentage = coSim(count_matrix)\n",
        "        matchPercentage = pd.DataFrame(matchPercentage, columns=['Skills Match'])\n",
        "\n",
        "        # Prepare results\n",
        "        result_cosine = df[['position', 'company']]\n",
        "        result_cosine = result_cosine.join(matchPercentage)\n",
        "        result_cosine = result_cosine[['position', 'company', 'Skills Match']]\n",
        "        result_cosine.columns = ['Job Title', 'Company', 'Skills Match']\n",
        "        result_cosine = result_cosine.sort_values('Skills Match', ascending=False).reset_index(drop=True)\n",
        "\n",
        "        # Add resume name and skills\n",
        "        result_cosine['Resume Name'] = os.path.basename(resume_file)\n",
        "        result_cosine['Skills'] = ', '.join(skills)\n",
        "\n",
        "        return result_cosine\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {resume_file}: {str(e)}\")\n",
        "        return pd.DataFrame(columns=['Job Title', 'Company', 'Skills Match', 'Resume Name', 'Skills'])"
      ],
      "metadata": {
        "id": "GlR0JTmEcEGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_zip_file(zip_path):\n",
        "    # Create a temporary directory for extracted files\n",
        "    temp_dir = \"temp_resumes\"\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    # Extract ZIP file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(temp_dir)\n",
        "\n",
        "    # Process all PDF files\n",
        "    all_results = []\n",
        "    for filename in os.listdir(temp_dir):\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            file_path = os.path.join(temp_dir, filename)\n",
        "            results = process_resume(file_path)\n",
        "            if not results.empty:\n",
        "                all_results.append(results)\n",
        "\n",
        "    # Combine all results\n",
        "    if all_results:\n",
        "        final_results = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "        # Remove duplicates and sort by Skills Match\n",
        "        final_results = final_results.drop_duplicates(subset=['Job Title', 'Company', 'Resume Name'])\n",
        "        final_results = final_results.sort_values('Skills Match', ascending=False)\n",
        "\n",
        "        # Format the output\n",
        "        pd.set_option('display.max_columns', None)\n",
        "        pd.set_option('display.width', None)\n",
        "        pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "        # Save to Excel with better formatting\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        excel_filename = f\"resume_analysis_results_{timestamp}.xlsx\"\n",
        "\n",
        "        try:\n",
        "            # Try using xlsxwriter first\n",
        "            with pd.ExcelWriter(excel_filename, engine='xlsxwriter') as writer:\n",
        "                final_results.to_excel(writer, sheet_name='Results', index=False)\n",
        "\n",
        "                # Get workbook and worksheet objects\n",
        "                workbook = writer.book\n",
        "                worksheet = writer.sheets['Results']\n",
        "\n",
        "                # Add formats\n",
        "                header_format = workbook.add_format({\n",
        "                    'bold': True,\n",
        "                    'text_wrap': True,\n",
        "                    'valign': 'top',\n",
        "                    'fg_color': '#D7E4BC',\n",
        "                    'border': 1\n",
        "                })\n",
        "\n",
        "                # Format the header\n",
        "                for col_num, value in enumerate(final_results.columns.values):\n",
        "                    worksheet.write(0, col_num, value, header_format)\n",
        "                    worksheet.set_column(col_num, col_num, 20)  # Set column width\n",
        "        except:\n",
        "            # Fallback to openpyxl if xlsxwriter fails\n",
        "            final_results.to_excel(excel_filename, index=False)\n",
        "\n",
        "        print(f\"\\nResults saved to {excel_filename}\")\n",
        "\n",
        "        # Clean up\n",
        "        import shutil\n",
        "        shutil.rmtree(temp_dir)\n",
        "\n",
        "        # Display results in a cleaner format\n",
        "        print(\"\\nAnalysis Results:\")\n",
        "        print(\"=\" * 80)\n",
        "        for _, row in final_results.iterrows():\n",
        "            print(f\"\\nResume: {row['Resume Name']}\")\n",
        "            print(f\"Job Title: {row['Job Title']}\")\n",
        "            print(f\"Company: {row['Company']}\")\n",
        "            print(f\"Skills Match: {row['Skills Match']}%\")\n",
        "            print(f\"Skills: {row['Skills']}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "        return final_results\n",
        "    else:\n",
        "        print(\"No valid PDF files found in the ZIP file\")\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will prompt you to upload your ZIP file\n",
        "\n",
        "# Get the filename of the uploaded ZIP file\n",
        "zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Process the ZIP file\n",
        "results = process_zip_file(zip_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "aUJtiJ9UcGTZ",
        "outputId": "8f920bb8-5cfa-4657-a094-edbfb72ee240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-447e5855-8e1f-4ee6-8319-e0ce69368789\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-447e5855-8e1f-4ee6-8319-e0ce69368789\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Espin Shalo Resume.pdf.zip to Espin Shalo Resume.pdf (2).zip\n",
            "\n",
            "Results saved to resume_analysis_results_20250428_081326.xlsx\n",
            "\n",
            "Analysis Results:\n",
            "================================================================================\n",
            "\n",
            "Resume: Espin Shalo Resume.pdf\n",
            "Job Title: Data Scientist\n",
            "Company: Data Analytics Inc\n",
            "Skills Match: 5.2%\n",
            "Skills: leadership, project management, python, flutter, time management, sql\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Resume: Espin Shalo Resume.pdf\n",
            "Job Title: Software Engineer\n",
            "Company: Tech Corp\n",
            "Skills Match: 4.92%\n",
            "Skills: leadership, project management, python, flutter, time management, sql\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Resume: Espin Shalo Resume.pdf\n",
            "Job Title: DevOps Engineer\n",
            "Company: Cloud Systems Inc\n",
            "Skills Match: 2.93%\n",
            "Skills: leadership, project management, python, flutter, time management, sql\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Resume: Espin Shalo Resume.pdf\n",
            "Job Title: Full Stack Developer\n",
            "Company: Web Solutions Ltd\n",
            "Skills Match: 0.0%\n",
            "Skills: leadership, project management, python, flutter, time management, sql\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Resume: Espin Shalo Resume.pdf\n",
            "Job Title: Frontend Developer\n",
            "Company: Creative Web Agency\n",
            "Skills Match: 0.0%\n",
            "Skills: leadership, project management, python, flutter, time management, sql\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_multiple_resumes(zip_path):\n",
        "    # Create a temporary directory for extracted files\n",
        "    temp_dir = \"temp_resumes\"\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    # Extract ZIP file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(temp_dir)\n",
        "\n",
        "    # Initialize lists to store all data\n",
        "    all_resume_data = []\n",
        "    all_job_matches = []\n",
        "\n",
        "    # Process each PDF file\n",
        "    for filename in os.listdir(temp_dir):\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            file_path = os.path.join(temp_dir, filename)\n",
        "            try:\n",
        "                # Extract resume text\n",
        "                resume_text = \" \".join(convert_pdf_to_txt(file_path))\n",
        "                skills = extract_skills(resume_text)\n",
        "\n",
        "                # Store resume data\n",
        "                resume_data = {\n",
        "                    'Resume Name': filename,\n",
        "                    'Skills Found': ', '.join(skills),\n",
        "                    'Total Skills': len(skills),\n",
        "                    'Processing Date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                }\n",
        "                all_resume_data.append(resume_data)\n",
        "\n",
        "                # Process against sample jobs\n",
        "                results = process_resume(file_path)\n",
        "                if not results.empty:\n",
        "                    # Add resume name to results\n",
        "                    results['Resume Name'] = filename\n",
        "                    all_job_matches.append(results)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "    if all_resume_data and all_job_matches:\n",
        "        # Create DataFrames\n",
        "        resume_df = pd.DataFrame(all_resume_data)\n",
        "        matches_df = pd.concat(all_job_matches, ignore_index=True)\n",
        "\n",
        "        # Remove duplicates and sort matches by Skills Match\n",
        "        matches_df = matches_df.drop_duplicates(subset=['Job Title', 'Company', 'Resume Name'])\n",
        "        matches_df = matches_df.sort_values('Skills Match', ascending=False)\n",
        "\n",
        "        # Create Excel writer\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        excel_filename = f\"comprehensive_resume_analysis_{timestamp}.xlsx\"\n",
        "\n",
        "        try:\n",
        "            with pd.ExcelWriter(excel_filename, engine='xlsxwriter') as writer:\n",
        "                # Write Resume Summary sheet\n",
        "                resume_df.to_excel(writer, sheet_name='Resume Summary', index=False)\n",
        "\n",
        "                # Write Job Matches sheet\n",
        "                matches_df.to_excel(writer, sheet_name='Job Matches', index=False)\n",
        "\n",
        "                # Get workbook and worksheet objects\n",
        "                workbook = writer.book\n",
        "\n",
        "                # Add formats\n",
        "                header_format = workbook.add_format({\n",
        "                    'bold': True,\n",
        "                    'text_wrap': True,\n",
        "                    'valign': 'top',\n",
        "                    'fg_color': '#D7E4BC',\n",
        "                    'border': 1\n",
        "                })\n",
        "\n",
        "                # Format Resume Summary sheet\n",
        "                worksheet1 = writer.sheets['Resume Summary']\n",
        "                for col_num, value in enumerate(resume_df.columns.values):\n",
        "                    worksheet1.write(0, col_num, value, header_format)\n",
        "                    worksheet1.set_column(col_num, col_num, 20)\n",
        "\n",
        "                # Format Job Matches sheet\n",
        "                worksheet2 = writer.sheets['Job Matches']\n",
        "                for col_num, value in enumerate(matches_df.columns.values):\n",
        "                    worksheet2.write(0, col_num, value, header_format)\n",
        "                    worksheet2.set_column(col_num, col_num, 20)\n",
        "\n",
        "                # Add a Summary sheet\n",
        "                summary_data = {\n",
        "                    'Metric': [\n",
        "                        'Total Resumes Processed',\n",
        "                        'Total Jobs Matched',\n",
        "                        'Average Skills per Resume',\n",
        "                        'Highest Skills Match %',\n",
        "                        'Lowest Skills Match %'\n",
        "                    ],\n",
        "                    'Value': [\n",
        "                        len(all_resume_data),\n",
        "                        len(matches_df),\n",
        "                        resume_df['Total Skills'].mean(),\n",
        "                        matches_df['Skills Match'].max(),\n",
        "                        matches_df['Skills Match'].min()\n",
        "                    ]\n",
        "                }\n",
        "                summary_df = pd.DataFrame(summary_data)\n",
        "                summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "                # Format Summary sheet\n",
        "                worksheet3 = writer.sheets['Summary']\n",
        "                for col_num, value in enumerate(summary_df.columns.values):\n",
        "                    worksheet3.write(0, col_num, value, header_format)\n",
        "                    worksheet3.set_column(col_num, col_num, 25)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating Excel file: {str(e)}\")\n",
        "            # Fallback to simple Excel writing\n",
        "            with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
        "                resume_df.to_excel(writer, sheet_name='Resume Summary', index=False)\n",
        "                matches_df.to_excel(writer, sheet_name='Job Matches', index=False)\n",
        "                summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "        print(f\"\\nComprehensive analysis saved to {excel_filename}\")\n",
        "\n",
        "        # Clean up\n",
        "        import shutil\n",
        "        shutil.rmtree(temp_dir)\n",
        "\n",
        "        # Display summary in a more readable format\n",
        "        print(\"\\nAnalysis Summary:\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"Total Resumes Processed: {len(all_resume_data)}\")\n",
        "        print(f\"Total Jobs Matched: {len(matches_df)}\")\n",
        "        print(f\"Average Skills per Resume: {resume_df['Total Skills'].mean():.2f}\")\n",
        "        print(f\"Highest Skills Match: {matches_df['Skills Match'].max():.2f}%\")\n",
        "        print(f\"Lowest Skills Match: {matches_df['Skills Match'].min():.2f}%\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # Display resume details in a cleaner format\n",
        "        print(\"\\nResume Details:\")\n",
        "        print(\"=\" * 80)\n",
        "        for _, row in resume_df.iterrows():\n",
        "            print(f\"\\nResume: {row['Resume Name']}\")\n",
        "            print(f\"Skills Found: {row['Skills Found']}\")\n",
        "            print(f\"Total Skills: {row['Total Skills']}\")\n",
        "            print(f\"Processing Date: {row['Processing Date']}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "        # Display top job matches in a cleaner format\n",
        "        print(\"\\nTop Job Matches:\")\n",
        "        print(\"=\" * 80)\n",
        "        for _, row in matches_df.iterrows():\n",
        "            print(f\"\\nJob Title: {row['Job Title']}\")\n",
        "            print(f\"Company: {row['Company']}\")\n",
        "            print(f\"Skills Match: {row['Skills Match']}%\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "        return resume_df, matches_df, summary_df\n",
        "    else:\n",
        "        print(\"No valid PDF files found in the ZIP file\")\n",
        "        return None, None, None\n",
        "\n",
        "# Example usage\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will prompt you to upload your ZIP file\n",
        "\n",
        "# Get the filename of the uploaded ZIP file\n",
        "zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Process multiple resumes\n",
        "resume_summary, job_matches, summary_stats = process_multiple_resumes(zip_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "id": "AezI9dD7cIYn",
        "outputId": "52d42005-916c-466b-aeff-3bdd442e435e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d3c54871-cff6-4c69-a24d-945c6a1428a3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d3c54871-cff6-4c69-a24d-945c6a1428a3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Espin Shalo Resume.pdf.zip to Espin Shalo Resume.pdf (8).zip\n",
            "\n",
            "Comprehensive analysis saved to comprehensive_resume_analysis_20250428_082418.xlsx\n",
            "\n",
            "Analysis Summary:\n",
            "================================================================================\n",
            "Total Resumes Processed: 1\n",
            "Total Jobs Matched: 5\n",
            "Average Skills per Resume: 6.00\n",
            "Highest Skills Match: 5.20%\n",
            "Lowest Skills Match: 0.00%\n",
            "================================================================================\n",
            "\n",
            "Resume Details:\n",
            "================================================================================\n",
            "\n",
            "Resume: Espin Shalo Resume.pdf\n",
            "Skills Found: leadership, project management, python, flutter, time management, sql\n",
            "Total Skills: 6\n",
            "Processing Date: 2025-04-28 08:24:18\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Top Job Matches:\n",
            "================================================================================\n",
            "\n",
            "Job Title: Data Scientist\n",
            "Company: Data Analytics Inc\n",
            "Skills Match: 5.2%\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Job Title: Software Engineer\n",
            "Company: Tech Corp\n",
            "Skills Match: 4.92%\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Job Title: DevOps Engineer\n",
            "Company: Cloud Systems Inc\n",
            "Skills Match: 2.93%\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Job Title: Full Stack Developer\n",
            "Company: Web Solutions Ltd\n",
            "Skills Match: 0.0%\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Job Title: Frontend Developer\n",
            "Company: Creative Web Agency\n",
            "Skills Match: 0.0%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}